{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.10 - [Práctica] Process the Forex rates with Spark – SparkSubmitOperator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://i.postimg.cc/DZqwc8KK/a592.png\"></center>\n",
    "\n",
    "Vamos a aprender cómo ejecutar un Spark job desde el data pipeline.\n",
    "\n",
    "Recuerda esto, Airflow es un orquestrador, por lo que no deberías procesar terabytes o gigabytes de datos en Airflow, en tu operador python. No debes hacer eso. En su lugar, deberías desencadenar (trigger) un Spark job donde el procesamiento de tus terabytes de datos está hecho, tu proceso está hecho en spark, y Airflow te permite desencadenar (trigger) ese Spark job. Pero no vas a procesar tus terabytes de datos en Airflow. De lo contrario, terminarás con un error de desbordamiento de memoria (memory overflow error). Y de nuevo, Airflow es un orquestador, el cual es el mejor orquestador, pero no lo confundas con el framework de procesamiento.\n",
    "\n",
    "Aquí está el script que vas a desencadenar (trigger) en Spark. No voy a entrar en detalles aquí, pero básicamente creas una 'SparkSession', luego lees el archivo 'forex_rates.json' de tu HDFS y luego haces algo de procesamiento en él para finalmente insertar los datos procesados en la \"forex rate hive table\" que has creado en el vídeo anterior. Pero ten en cuenta que este script te permite insertar los datos de tu archivo 'forex_rates.json', en la tabla Hive que has creado.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/K8wcSnG2/a593.png\"></center>\n",
    "\n",
    "Aquí están los pocos parámetros que tiene que especificar. Primero, el '**`task_id`**', como siempre, como cualquier otro operator, tienes que especificar el task_id. El segundo parámetro es '**`application`**', application es la ruta del script que vas a ejecutar. Luego el '**`connection_id`**', el id de la conexión para interactuar con Spark. Por último, puedes especificar '**`verbose = False`**' para evitar producir demasiados logs. De lo contrario, será más difícil buscar la información que queremos de los logs. Así que pon '**`verbose = False`**'.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/VkdsV7cg/a594.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/sxmftqX6/a595.png\"></center>\n",
    "\n",
    "Ahora nos dirigimos a la UI de Airflow y creamos una nueva conexión:\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/kMv566cQ/a596.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Prf5mX3B/a597.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/9FxFb6sz/a598.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
