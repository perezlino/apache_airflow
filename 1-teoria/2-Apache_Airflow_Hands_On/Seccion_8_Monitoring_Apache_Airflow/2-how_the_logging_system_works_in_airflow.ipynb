{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.2 - How the logging system works in Airflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this video you are going to learn exactly how the logging system of Airflow works.\n",
    "\n",
    "Let's begin with the basics.\n",
    "\n",
    "The logging system of Airflow is based on the Python standard library logging offering you a lot of\n",
    "\n",
    "flexibility in terms of configuration.\n",
    "\n",
    "Just to give you a little reminder, logs are described as the stream of aggregated, time-ordered events\n",
    "\n",
    "collected from the output streams of all running processes and backing services.\n",
    "\n",
    "As you know, Airflow relies on many components such as a web server, a scheduler and one to many workers.\n",
    "\n",
    "Each component generates its own stream of logs which will be stored into a file by default by using\n",
    "\n",
    "the logging module.\n",
    "\n",
    "This module allows to create a logger object which is in charge of obtaining the logs we want according\n",
    "\n",
    "to a defined log level such as INFO, DEBUG, ERROR or WARNING.\n",
    "\n",
    "Then, the logs is formatted according to the configuration set in the file airflow.cfg as we will see\n",
    "\n",
    "later.\n",
    "\n",
    "Finally, these logs are redirected to a specified destination depending on the Handler used. A Handler\n",
    "\n",
    "is basically an object deciding what happens with the log.\n",
    "\n",
    "There are many Handlers available but the most important ones are the FileHandler, StreamHandler and\n",
    "\n",
    "NullHandler. The FileHandler writes output to a disk file. The StreamHandler writes output to a stream\n",
    "\n",
    "like the standard output, and the NullHandler does nothing.\n",
    "\n",
    "It is useful only for testing and developing so actually you should never use it unless you are a contributor\n",
    "\n",
    "of Airflow. By default,\n",
    "\n",
    "the FileHandler is set and the logs are stored at the destination specified in the parameter base\n",
    "\n",
    "_log_folder in airflow.cfg.\n",
    "\n",
    "It is possible to change the handler in order to customize your Airflow logging system. Just to give\n",
    "\n",
    "you a better idea of how the logging system is created,\n",
    "\n",
    "here are the different steps as shown directly from the code.\n",
    "\n",
    "First, a logger object is fetched from the logger module.\n",
    "\n",
    "Then the handler and formatter are instantiated.\n",
    "\n",
    "Notice the parameter SIMPLE_LOG_FORMAT given to the formatter. This parameter\n",
    "\n",
    "can be found in the airflow.cfg file and it allows you to specify how to format the output of your\n",
    "\n",
    "logs if you want to\n",
    "\n",
    "add the time, the loglevel and so on.\n",
    "\n",
    "Next, the formatter is set to the handler and the handler is set to the logger object.\n",
    "\n",
    "Finally, the LOG_LEVEL parameter is applied to the logger in order to filter the logs according to the\n",
    "\n",
    "level set such as INFO, WARNING, DEBUG and so on.\n",
    "\n",
    "Now we have seen how the logger system is set up,\n",
    "\n",
    "here is an overview of how it works.\n",
    "\n",
    "So, the logger object is created and initialised as we have seen previously. When a component of Airflow wants\n",
    "\n",
    "to print out a log,\n",
    "\n",
    "it calls the logger object with the method corresponding to the log level of that log.\n",
    "\n",
    "In this example, “dependencies all met” is an informational log so the method info is called.\n",
    "\n",
    "If the LOG_LEVEL parameter in your airflow.cfg file is set to the level INFO then you will be\n",
    "\n",
    "able to see that log.\n",
    "\n",
    "Then, before the log gets stored at the default location /usr/local/airflow/logs by\n",
    "\n",
    "the FileHandler, it is processed by the Formatter to apply the correct format.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Many handlers are available in Airflow. Thanks to them, we can write the logs at different locations such\n",
    "\n",
    "as the standard output, AWS S3, ElasticSearch, GCS and so on.\n",
    "\n",
    "Some of these handlers require a connection such as S3 and GCS.\n",
    "\n",
    "Since there are external storages, the parameter REMOTE_LOG_CONN_\n",
    "\n",
    "ID must be set with the connection to the system and the parameter REMOTE_LOGING must\n",
    "\n",
    "be set to true as well.\n",
    "\n",
    "Alright, now you know how the logging system works\n",
    "\n",
    "it’s time to move to the practice part. See you in the next video.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
