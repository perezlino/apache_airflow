{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **8.7 - [Practica] Monitoring Airflow with TIG stack**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s set up the TIG stack in order to monitor Airflow. First, check that you are under the folder airflow\n",
    "\n",
    "materials/airflow-section-8 and open the file docker-compose-CeleryExecutor\n",
    "\n",
    "TIG.yml. As usual, we have the different services to run Airflow with the CeleryExecutor. If\n",
    "\n",
    "you scroll down,\n",
    "\n",
    "you will reach the services of the TIG stack. Here,\n",
    "\n",
    "there is Telegraf with a volume to bind the configuration file telegraf.conf from mnt\n",
    "\n",
    "/telegraf to the service.\n",
    "\n",
    "We will take a look at it in a minute. Just below, the InfluxDB service is initialized with default\n",
    "\n",
    "ports set.\n",
    "\n",
    "Finally, Grafana is defined as well on the port 3000.\n",
    "\n",
    "Now let’s configure Telegraf. Open the file telegraf.conf in mnt/telegraf and look for\n",
    "\n",
    "the section “outputs.influxdb”.\n",
    "\n",
    "As you can see all the lines below\n",
    "\n",
    "this comment correspond to the output plugins.\n",
    "\n",
    "There are predefined and the only thing you have to do is uncomment what you want to turn on.\n",
    "\n",
    "By default, the output influxdb is enabled but we have to configure it. First, uncomment the third line\n",
    "\n",
    "“urls”, and replace the ip address to “influxdb”.\n",
    "\n",
    "Remember that the values here correspond to the service name and the port of InfluxDB in the docker\n",
    "\n",
    "compose file.\n",
    "\n",
    "Next, uncomment the line with “database” in order to specify the target database where the metrics will\n",
    "\n",
    "be set\n",
    "\n",
    "which is “telegraf” by default. Uncomment the parameter skip_database_creation\n",
    "\n",
    "and set it to “True”\n",
    "\n",
    "since we are going to create the database by ourselves from the container of InfluxDB. Then, uncomment\n",
    "\n",
    "the parameters timeout to define a timeout for HTTP messages.\n",
    "\n",
    "Just below,\n",
    "\n",
    "we uncomment username and password in order to define the user account that will be used by Telegraf\n",
    "\n",
    "to send metrics into InfluxDB. Let’s keep the username “telegraf” and change the password to “telegraf\n",
    "\n",
    "pass”.\n",
    "\n",
    "Like that. Uncomment the user-agent as well. And that’s it,\n",
    "\n",
    "the output plugin InfluxDB is configured and Telegraf is ready to send data to it. So, the output\n",
    "\n",
    "is set but the input where Telegraf will receive the metrics coming from Airflow is still missing.\n",
    "\n",
    "Let's fix this.\n",
    "\n",
    "Look for the section “inputs.statsd”\n",
    "\n",
    "and let’s uncomment all the lines of the section.\n",
    "\n",
    "Like that.\n",
    "\n",
    "I’m not going to explain each parameter since there is already a description above each one but basically\n",
    "\n",
    "Telegraf will start a StatsD daemon listening on the port 8125 in UDP for metrics coming from Airflow.\n",
    "\n",
    "Save the file and let’s configure Airflow so that it will send the metrics to Telegraf. Open the file\n",
    "\n",
    "airflow.cfg and look for the section “statsd”. Here\n",
    "\n",
    "there are 4 parameters that you have to define.\n",
    "\n",
    "First, change the value of statsd_on from False to True in order to activate it.\n",
    "\n",
    "Then, replace localhost here, by telegraf which is the name of the container running\n",
    "\n",
    "Telegraf.\n",
    "\n",
    "Finally, keep the two last parameters with their default values.\n",
    "\n",
    "Perfect, now Airflow is configured to send its metrics into the input plugin statsd of Telegraf. Last thing,\n",
    "\n",
    "look for the parameter remote_logging\n",
    "\n",
    "and set it to False\n",
    "\n",
    "if it’s not already done. Since we are not going to store the log files in a remote storage, there is\n",
    "\n",
    "no need to keep it active.\n",
    "\n",
    "Save the file.\n",
    "\n",
    "All right.\n",
    "\n",
    "Time to start everything.\n",
    "\n",
    "Open your terminal, and check that you are under the folder airflow-materials/airflow-section\n",
    "\n",
    "-8 and type “docker-compose -\n",
    "\n",
    "f\n",
    "\n",
    "docker-compose-CeleryExecutorTIG.yml up -d”.\n",
    "\n",
    "Enter.\n",
    "\n",
    "Wait a second or two.\n",
    "\n",
    "Type “docker ps” to check that everything is running.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "Now we have to create the database telegraf as well as the user telegraf in InfluxDB which will\n",
    "\n",
    "be used by telegraf for sending the metrics. Type “docker exec\n",
    "\n",
    "-it”\n",
    "\n",
    "copy and past the container id of InfluxDB,\n",
    "\n",
    "and type “influx”.\n",
    "\n",
    "Enter.\n",
    "\n",
    "And here we are connected to InfluxDB through the InfluxDB shell as shown here.\n",
    "\n",
    "Type “create database telegraf”\n",
    "\n",
    "Enter. Ok then create the user by executing “create user telegraf\n",
    "\n",
    "with password\n",
    "\n",
    "‘telegrafpass’”\n",
    "\n",
    "Enter. And the user telegraf is created. Exit the docker container by hitting control-D, and open your\n",
    "\n",
    "web browser. Type “localhost:3000”.\n",
    "\n",
    "Enter. Type “admin” for both login and password.\n",
    "\n",
    "Then “Log In”. We skip the step, and we land on the beautiful Grafana dashboard. From there, there are two\n",
    "\n",
    "steps we need to follow as shown here. Let’s add a data source corresponding to the InfluxDB instance\n",
    "\n",
    "we set up where the metrics of Airflow are stored. Click on “add data source”. Then select “InfluxDB”. Ok.\n",
    "\n",
    "The URL is “http://influxdb:8086”.\n",
    "\n",
    "Next.\n",
    "\n",
    "under the section InfluxDB details, the database is “telegraf”,\n",
    "\n",
    "the user is “telegraf” as well.\n",
    "\n",
    "And the password is defined to “telegrafpass”.\n",
    "\n",
    "I advise to add the “pass” here and just copy and paste the value so that you are sure the password\n",
    "\n",
    "is correct.\n",
    "\n",
    "Okay,\n",
    "\n",
    "check that you have the settings as mine and click on “save and test”.\n",
    "\n",
    "If everything works fine you should obtain the same message here telling you that the data source is\n",
    "\n",
    "working.\n",
    "\n",
    "Go back to the Grafana homepage by clicking here then “new dashboard” and “add query”.\n",
    "\n",
    "Here, you have to define the query that will fetch the metrics you want from InfluxDB.\n",
    "\n",
    "For example, if we click on “select measurement”. All the measurements prefixed by “airflow_” correspond\n",
    "\n",
    "to the different metrics available of Airflow. Before moving forward,\n",
    "\n",
    "open a new tab, and go to “https://\n",
    "\n",
    "airflow.apache.org\n",
    "\n",
    "/docs/stable/metrics.html”.\n",
    "\n",
    "If you scroll down, you obtain the list of metrics as well as their descriptions all divided by types as\n",
    "\n",
    "shown here.\n",
    "\n",
    "Let’s say we want to know the number of DAGs loaded by Airflow. Under “Gauges” the metric dagbag\n",
    "\n",
    "_size gives us this information. Since a dabbag corresponds to the loaded DAGs of the scheduler,\n",
    "\n",
    "we actually need to active the different DAGs. Open a new tab, and type localhost:8080.\n",
    "\n",
    "Enter. Then here,\n",
    "\n",
    "turn on the toggle of both DAGs.\n",
    "\n",
    "Perfect.\n",
    "\n",
    "So back to Grafana,\n",
    "\n",
    "select “airflow_dagbag_size”. Like that. Click on mean\n",
    "\n",
    "here, “remove”. Click on the “plus”, “Selector” and “last”, so that we obtain last number of loaded DAGs\n",
    "\n",
    "by the scheduler.\n",
    "\n",
    "Remove the group by since the last number is fetched from the entire table. Then from left click on\n",
    "\n",
    "“Visualization”, select the Gauge. Under display, click on Mean, Select Last, and we obtain a beautiful gauge\n",
    "\n",
    "with the number 2 corresponding to dags logger_dag and data_dag imported\n",
    "\n",
    "by airflow.\n",
    "\n",
    "Here, you can customize the visualization if you want by setting the display,\n",
    "\n",
    "the thresholds and so on. Next, click on “General” and set the title “Number of imported DAGs” so that\n",
    "\n",
    "we know the meaning of the chart.\n",
    "\n",
    "Okay.\n",
    "\n",
    "Finally, at the top of the page, click on “Save dashboard”,\n",
    "\n",
    "give the name “Airflow”,\n",
    "\n",
    "click on “Save”. And you just have create your Dashboard for monitoring your Airflow instance with Grafana,\n",
    "\n",
    "InfluxDB and Telegraf.\n",
    "\n",
    "Well done! All right,\n",
    "\n",
    "keep everything running and see you in the next video where I will show you how to be alerted if anything\n",
    "\n",
    "goes wrong.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
