{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.9 - How to structure your DAG Folder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La carpeta DAG es donde pondrá todos sus archivos python correspondientes a sus DAGs. Su ubicación se da a través del parámetro dags_folder en el archivo de configuración airflow.cfg. Por defecto, Airflow utilizará la ruta dada desde la variable de entorno AIRLFOW_HOME con /dags al final. Por último, observe que esta ruta debe ser absoluta.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/GhqSXyGJ/a688.png\"></center>\n",
    "\n",
    "Muy bien, ahora sabemos eso, la pregunta es, qué podemos hacer si tenemos muchos DAGs usando archivos externos en la carpeta DAG para mantenerla bien organizada. Bueno, en mi opinión hay dos maneras de abordar este problema. Empecemos por la primera. Cuando necesites combinar un dag con sus dependencias una forma muy práctica de hacerlo es utilizando archivos zip. Por ejemplo, podrías querer combinar varios dags juntos para versionarlos o quizás necesites un módulo extra que no está disponible por defecto en el sistema que está ejecutando airflow en, a continuación, empaquetando (packaging) su dag en un archivo zip puede ser una gran solución. Una vez que haya creado su paquete, Airflow escaneará la carpeta de dags y cargará los dags del archivo zip. El único requisito es que sus dags deben colocarse en la raíz (root) del archivo zip, de lo contrario, Airflow no podrá cargarlos. Otra cosa que puedes hacer es usar virtualenv junto con pip que te permite añadir dependencias de módulos. Básicamente, primero crearás tu entorno virtual de python y lo activarás. Luego, crearás la carpeta donde estarán tus dags e instalarás los diferentes paquetes que quieras con pip. Por último, comprimes la carpeta (zip the folder), la mueves a la carpeta dags y ya está. No te preocupes si ahora es confuso, como siempre, vamos a ver un ejemplo en el siguiente video. En la imagen de abajo, puedes ver un ejemplo de el contenido de un archivo zip. En resumen, los archivos zip pueden ser muy buenos para agrupar tus DAGs junto con sus dependencias. Además, podemos imaginar un pipeline CI/CD produciendo un archivo zip en su carpeta dags después de haber probado y aprobado los dags.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Crea un archivo zip con tus Dags`**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Bnb7knCW/a689.png\"></center>\n",
    "\n",
    "Bien, ahora que hemos visto cómo organizar tu carpeta dags con archivos zip, vamos a ver cómo hacerlo con DagBags.\n",
    "\n",
    "Primero, ¿qué es un DagBag?\n",
    "\n",
    "Un DagBag corresponde a una clase que tiene una colección de DAGs, analizados desde una carpeta determinada con su propia configuración. Por defecto, cuando se inicia Airflow, se crea un DagBag utilizando el executor y la carpeta dags especificados en el archivo de configuración airflow.cfg. Lo veremos en los logs del servidor web.\n",
    "\n",
    "Entonces, ¿qué podemos hacer con DagBags?\n",
    "\n",
    "Bueno, al utilizar DagBags podrás cargar tus Dags desde diferentes carpetas y no sólo en la establecida por defecto. Por ejemplo, usted todavía necesita tener la carpeta dags, pero podría tener otra carpeta en cualquier ubicación que desee, siempre y cuando Airflow tenga acceso a ella, y cargar sus dags desde esa carpeta. Lo verás en el video práctico, pero para activar esta característica necesitaremos tener un archivo especial de python. Eso no quiere decir que sea un truco ya que también se da desde la documentación oficial. Dos advertencias sobre esta técnica, si un dag cargado desde otra carpeta se rompe, usted no será capaz de ver los errores desde el Airflow UI. Usted tendrá que comprobar los logs del webserver. Además, no podrá ver este dag desde el comando \"airflow list_dags\". Estas son las dos limitaciones que he encontrado hasta ahora y que no son realmente molestas en comparación con los beneficios que puede obtener de esta técnica. No hay una mejor práctica para organizar su carpeta de dags ya que realmente depende de su equipo y proyectos. Sólo trata de mantener las cosas lo suficientemente claras para que no te pierdas en tus dags y para saber cuál interactúa con el otro.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Crea un DagBag`**\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/SxP1hbZn/a690.png\"></center>\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Usa el archivo .airflowignore`**\n",
    "\n",
    "La última cosa de la que quiero hablar es el archivo .airflowignore. **`Este archivo es exactamente como el archivo .gitignore que tienes en tus repositorios git. Es decir, cualquier cosa que pongas ahí, será ignorada por Airflow`**. Por ejemplo, digamos que tienes la carpeta my_files que contiene scripts de python en tu carpeta dags y no quieres que sea escaneada por Airflow ya que no contiene ningún DAG, sólo tienes que añadirlo en el archivo .airflowignore. Cada línea es un patrón de expresión regular, por lo que puede utilizar patrones en lugar de coincidencias exactas. Este archivo debe colocarse en la carpeta dags y su alcance se limita a la carpeta actual donde se encuentra y sus subcarpetas. Debe saber que Airflow busca periódicamente en la carpeta dags para obtener nuevos dags. Este proceso puede malgastar inútilmente recursos al escanear archivos que no son DAGs. Por lo tanto, como mejor práctica, si sabe que un archivo determinado no es un DAG o que una carpeta determinada no contiene ningún DAG, debe ponerlo en el archivo .airflowignore. Crea siempre un archivo .airflowignore en tu carpeta dags aunque esté vacía.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/CKfPMrtm/a691.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
