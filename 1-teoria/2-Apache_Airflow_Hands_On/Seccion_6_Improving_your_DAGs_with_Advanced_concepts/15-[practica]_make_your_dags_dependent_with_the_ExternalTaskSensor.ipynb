{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.15 - [Practica] Make your DAGs dependent with the ExternalTaskSensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es hora de ver el ExternalTaskSensor en acción y hacer tu primera dependencia entre dos DAGs. Desde tu editor de código, comprueba que estás en la carpeta airflow-materials/airflow-section-6. Ok, abre el archivo \"externaltasksensor_dag.py\". \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/WbKhCvv8/a1073.png\"></center>\n",
    "\n",
    "Este DAG se compone de dos tareas \"sensor\" y \"last_task\".  Centrémonos en \"sensor\".  Como puedes ver, el ExternalTaskSensor se instancia con los parámetros \"external_dag_id\" y \"external_task_id\".  Como puedes adivinar, el primero corresponde al dag id donde está la tarea que estamos vigilando y el segundo corresponde al task id de esa tarea. En resumen, estamos esperando a que termine la tarea t2 en el dag \"sleep_dag\" para iniciar la siguiente tarea \"last_task\" en este DAG. Ahora, si abrimos el archivo \"sleep_dag.py\", tenemos nuestro segundo DAG con dos tareas también.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/pT2TzVfW/a1074.png\"></center>\n",
    "\n",
    "\"t1\" no hace nada y \"t2\" ejecuta el bash command sleep para pausar el DAG durante 30 segundos. Antes de programar los DAGs, observa que \"start_date\" y \"schedule_dag\" son iguales.  Ok, vamos a abrir tu terminal e iniciar los contenedores docker ejecutando Airflow con el comando \"docker-compose -f docker-compose-CeleryExecutor.yml up -d\".  Ok, ahora abre tu navegador web y escribe localhost:8080. Enter. Desde ahí, activa el toggle del dag \"externaltasksensor_dag\" y \"sleep_dag\".  No olvides que la ejecución del DAG \"externaltasksensor_dag\" depende de la ejecución de la tarea t2 del DAG \"sleep_dag\".  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/R0xqCLqn/a1075.png\"></center>\n",
    "\n",
    "Ahora empieza a refrescar la página y mira lo que está pasando. Como puedes observar en las tareas, las tareas del DAG \"sleep_dag\" se están completando mientras que en el DAG \"externaltasksensor\" sólo se está ejecutando la tarea correspondiente al sensor. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/P5wPkRfj/a1076.png\"></center>\n",
    "\n",
    "Si seguimos refrescando la página, en algún momento la tarea t2 terminará y el sensor también tendrá éxito.  Entonces, se disparará la siguiente tarea del dag \"externaltasksensor_dag\", \"last_task\".  Eso es lo que obtenemos aquí.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/hG8vXQ7Z/a1077.png\"></center>\n",
    "\n",
    "Así que eso es todo, como puedes ver es bastante simple crear una dependencia entre dos DAGs.  Si quieres tener más detalles sobre cómo utilizar el ExternalTaskSensor, no dudes en contactarme en la sección Q/A de Udemy estaré encantado de darte más información. De vuelta a tu terminal, no olvides parar Airflow con el comando \"docker-compose -f docker-compose-CeleryExecutor.yml down\".  Muy bien, vamos a tomar un breve descanso ahora y nos vemos en el próximo vídeo.   "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
