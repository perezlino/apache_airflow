{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6.7 - [Practica] Changing how your tasks are triggered**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el vídeo anterior hemos visto varias \"trigger rules\" que puedes aplicar a tus tareas para modificar su forma de ejecución.  En este vídeo voy a hacer un pequeño ejercicio para ti.  Aquí tienes el pequeño DAG que quiero que implementes utilizando dependencias y trigger rules.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/RFSqXmYG/a980.png\"></center>\n",
    "\n",
    "Al principio, tenemos dos tareas download_website_A y download_website _B que se pueden ejecutar en paralelo.  Entonces, la tarea download_failed se disparará si ambas tareas de descarga han fallado, de lo contrario, si han tenido éxito, se ejecutará la tarea download_succeed. Ambas tareas dependen de download_website_A y download_website_B.  A continuación, la tarea process se activa tan pronto como la tarea download_failed o download_succeed haya tenido éxito.  Por último, la tarea notif_a espera a que la tarea padre haya tenido éxito o haya sido omitida para ejecutarse, mientras que la tarea notif_b se ejecuta tan pronto como el proceso de la tarea haya fallado.  Así que ahora que tienes las trigger rules que tienes que añadir para cada tarea con un texto encima, déjame darte más información que te será útil para este ejercicio.  Desde tu editor de código, comprueba que el archivo trigger_rule_dag.py está abierto y que te encuentras en la carpeta airflow-materials/airflow-section-6. En este archivo, ya he implementado las diferentes funciones y tareas que necesitas.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/LsT8q7sP/a981.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/FH0Rv15D/a982.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/9MQFyp4n/a983.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/pV1yYgJY/a984.png\"></center>\n",
    "\n",
    "Así que, si te desplazas hacia abajo, aquí tienes la tarea dowload_website_a que es un PythonOperator llamando a la función download_website_a con la trigger rule \"all_success\" que es la regla por defecto. La función download_website_a, está al principio del archivo, aquí, y no hace nada más que imprimir el nombre de la función en la salida estándar.  Fíjate que he dejado una instrucción para lanzar una excepción en comentario.  ¿Por qué?  Porque si deseas verificar cómo se comportan tus tareas en caso de que todos los padres o sólo uno de los padres fallen, entonces para hacer que fallen, sólo necesitarás descomentar esta línea.  Por último, en la parte inferior del DAG, justo debajo de este comentario, aquí es donde vas a crear las dependencias.  Ok, déjame mostrarte como proceder para terminar este ejercicio.  Primero necesitas tener el mismo DAG que se muestra al principio del video estableciendo las dependencias.  Así que vamos a ver lo que tenemos sin definir nada.  Abre tu terminal, y comprueba que estás bajo la carpeta airflow-materials/airflow-section-6 e inicia los contenedores docker ejecutando airflow con el comando \"docker-compose -f docker-compose-CeleryExecutor.yml up -d\". Enter. Ok, ahora que los contenedores docker se están ejecutando, vaya a su navegador web y escriba \"localhost:8080\".  Enter. Haz click en el DAG trigger_rule_dag y \"Graph View\". Como puedes ver tenemos un montón de tareas que no están vinculadas entre sí. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KjVzGM8s/a985.png\"></center>\n",
    "\n",
    "Vamos a crear la dependencia entre las tareas download _failed, download_success y process. Desde tu editor, al final del DAG escribimos \"[download_failed_task, download_succeed_task] >> process_task\".   Guarde el archivo y vaya a la interfaz de usuario de Airflow.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/fTGL1mFV/a986.png\"></center>\n",
    "\n",
    "Desde allí, actualiza el DAG pulsando este botón. Y las dependencias entre las tareas se han aplicado como se puede ver aquí. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/sDQxnwnF/a987.png\"></center>\n",
    "\n",
    "Volviendo al DAG, cuando pones tareas dentro de corchetes como esos, es como si crearas un grupo de tareas que puedes enlazar con otras tareas.  Observa que podríamos escribir \"download_failed_task >> process_task\" y \"download_succeed_task >> process_task\" en lugar de usar los corchetes, ambas expresiones producen el mismo resultado.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/BvsvnsJs/a988.png\"></center>\n",
    "\n",
    "Depende de ti elegir una forma u otra.  Muy bien. Ahora es el momento de que intentes crear el mismo DAG que se muestra aquí.  No olvides que tienes que cambiar la trigger rule de cada tarea basándote en la descripción anterior.  Así que pausa el video y nos vemos para la solución.  Muy bien, espero que hayas intentado hacer el ejercicio así que vamos a hacerlo juntos.  Primero vamos a empezar por crear las dependencias. \"download_website_a\" y \"download_website_b\" son tareas upstream tanto de \"download_ failed\" como de \"download_succeed\".  Así que escribimos \"[download_website_a_task, download_website_b_task] >> download_failed_task y en una nueva línea [download_website_a_task, download_website_b_task] >> download_succeed_task\". Guarde el archivo. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DyXfQmZn/a989.png\"></center>\n",
    "\n",
    "A continuación, desde la interfaz de usuario de Airflow, refrescamos el DAG haciendo clic en este botón. Perfecto.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/brKycfm7/a990.png\"></center>\n",
    "\n",
    "Ahora tenemos que añadir las dependencias entre process, notif_a y notif_b.  Así que, en el código, escribimos process_task >> [notif_a_task , notif_b_task\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Bn5qyyHz/a991.png\"></center>\n",
    "\n",
    "Guardamos el archivo, refrescamos el DAG desde la UI, y obtenemos el mismo DAG que el de la diapositiva.  Perfecto.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/FHXrTmdc/a992.png\"></center>\n",
    "\n",
    "Ahora es el momento de modificar las trigger rules.  Empecemos con la tarea download_failed_task. Esta tarea debe dispararse si todos los padres han fallado. En el vídeo anterior hemos visto que la trigger rule que describe este comportamiento es \"all_failed\".  Así que aquí, cambiamos el valor de all_success a all_failed.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/63qt8pgs/a993.png\"></center>\n",
    "\n",
    "Bien, siguiente. La tarea \"download_succeed_task\" se activa si todos los padres han tenido éxito.  Como es el comportamiento por defecto, mantenemos el valor \"all_success\". Luego, la tarea \"process\" se ejecuta tan pronto como uno de los padres ha tenido éxito sin esperar a que las otras tareas terminen.  Si recuerdas, la trigger rule correspondiente a esta descripción es \"one_success\".  Así que cambiamos a “one_success”. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/LXWRLMFJ/a994.png\"></center>\n",
    "\n",
    "La tarea notif_a debe activarse sólo si ninguno de los padres ha fallado.  Es decir, los padres pueden estar en estado de éxito o de omisión.  Esto corresponde a la trigger rule \"none_failed\".  Así que cambiamos la regla de \"all_success\" a \"none_failed\".  Finalmente, la última tarea, \"notif_b\" debe ejecutarse tan pronto como al menos uno de los padres haya fallado, lo que corresponde a la trigger rule \"one_failed\".  De acuerdo. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/FzFHmQXz/a998.png\"></center>\n",
    "\n",
    "Así que hemos terminado, guarde el archivo y vaya a la interfaz de usuario de Airflow para activar el DAG. Actualiza el DAG, enciende el toggle del DAG y haz click en \"Trigger DAG\" aquí.  Ahora empieza a refrescar la página hasta que el DAGRun haya terminado.  Muy bien, echemos un vistazo al Graph view.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/1z99ZHK3/a995.png\"></center>\n",
    "\n",
    "Como puedes ver, la tarea download_failed ha sido omitida ya que las tareas download_ website_a y download_website_b han tenido éxito. Y la tarea notif_b también se ha omitido ya que el proceso no falló.  De acuerdo.  La última pregunta que quiero hacerte es, ¿qué va a pasar si las tareas \"download_website_a\" y \"download_website_b\" fallan?  Bien, vamos a verificarlo lanzando una excepción desde cada una de estas tareas.  De vuelta al DAG, en la función \"download_website_a\", descomenta la línea de aquí, y haz lo mismo para la función \"download_website_b\". \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/j2JThkRZ/a996.png\"></center>\n",
    "\n",
    "Bien, ahora guarde el archivo y vaya a la interfaz de usuario de Airflow. Desde allí, actualice el DAG haciendo clic aquí, y active el DAG una vez más.  Ahora que el DAG se está ejecutando, comience a refrescar la página hasta que el DAGRun haya terminado.  Bien, si echamos un vistazo al Graph view, podemos ver que las tareas download_website han fallado como se esperaba, por lo tanto, la tarea download_failed ha sido disparada.  Las otras tareas se siguen ejecutando como antes.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/23RD9F6m/a997.png\"></center>\n",
    "\n",
    "Muy bien, eso es todo por este video.  No olvides detener los contenedores docker que ejecutan Airflow abriendo tu terminal y escribiendo \"docker-compose - f docker-compose-CeleryExecutor.yml down\".  Enter.  Ya está.  Espero que hayas disfrutado jugando con las \"trigger rules\".  Te recomiendo encarecidamente que hagas tus propios experimentos mezclando dependencias y reglas de trigger para que veas lo potente y flexible que puede ser Airflow.  Tomemos un breve descanso y nos vemos en el próximo vídeo.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
