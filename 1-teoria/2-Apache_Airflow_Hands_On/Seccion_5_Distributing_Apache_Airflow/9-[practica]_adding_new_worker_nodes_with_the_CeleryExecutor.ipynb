{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5.9 - [Practica] Adding new worker nodes with the Celery Executor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el vídeo anterior hemos visto cómo distribuir las tareas de un DAG dado a los nodos worker.  Hemos establecido el parámetro worker_concurrency en 1 para que sólo se pueda ejecutar una tarea por nodo worker.  En este vídeo te voy a mostrar cómo aumentar el número de tareas ejecutadas añadiendo nuevos nodos a tu cluster.  Al principio, **vamos a añadir manualmente un nuevo nodo** para que puedas hacerlo sea cual sea tu arquitectura, y luego te mostraré cómo hacerlo con docker compose.  Bien, desde tu terminal, comprueba que estás en la carpeta airflow-materials/airflow-section-5. Con **`\"docker ps\"`**, podemos ver que no hay contenedores docker en ejecución, así que vamos a iniciar Airflow. Para ello, escribe **`\"docker-compose -f docker-compose-CeleryExecutor.yml up -d\"`**. Enter. Ok, entonces verificamos que todo se está ejecutando con \"docker ps\".  Como se puede ver en la salida, sólo tenemos un nodo worker. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/FHCK81h7/a846.png\"></center>\n",
    "\n",
    "Digamos que tienes una nueva máquina que te gustaría integrar a tu cluster.  ¿Cómo puedes hacerlo? **Bueno, en nuestro caso, una máquina es un contenedor docker así que vamos a crear un nuevo contenedor**.  Tenga en cuenta que lo que voy a mostrar es exactamente lo que haría con una nueva máquina real como una instancia EC2.  Así que, como Airflow está basado en Python, usaremos la imagen docker python 3.7. Escribimos **`docker run python :3.7`**.  Bien.  Cuando iniciamos múltiples contenedores docker usando docker-compose, se crea una red compartida para que todos los contenedores que componen la aplicación puedan hablar entre sí.  Eso es lo que puedes ver en la línea de aquí que te dice que se ha creado una red llamada \"airflow-section-5_default\" con el controlador por defecto (default driver). \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/BQQLVr27/a847.png\"></center>\n",
    "\n",
    "Como queremos que el nuevo nodo forme parte del cluster, tenemos que adjuntarlo con la misma red.  Así que escribe \"**`docker run --network airflow-section-5_default`**\".  A continuación, tenemos que exponer (expose) el puerto utilizado por Airflow para servir los archivos worker local log al web server principal de Airflow.  Añada la opción \"**`--expose 8793`**\".  Si se preguntas dónde está definido este puerto, puede echar un vistazo en airflow.cfg y buscar el parámetro \"worker_log_server_port\".  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/7YsG8KVH/a848.png\"></center>\n",
    "\n",
    "A continuación, tenemos que enlazar dos volúmenes correspondientes a la carpeta \"dags\" y al archivo airflow.cfg para que el nuevo nodo tenga la misma configuración y dags que los demás nodos del clúster. Escriba **`\"-v ./mnt/airflow/dags:/usr/local/airflow/dags\" y \"-v ./mnt/airflow/airflow.cfg:/usr/local/airflow/airflow.cfg\"`**.  De acuerdo. Hay una trampa aquí. De hecho, la opción **-v** no soporta rutas relativas. Así que tenemos que reemplazar los puntos aquí y aqui con la ruta absoluta. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/GhBgG59V/a849.png\"></center>\n",
    "\n",
    "En mi caso es /Users/Marc/airflow-materials/airflow-section-5. Encuentra la tuya escribiendo pwd o usando tu explorador de archivos.  Entonces reemplazo los puntos. Perfecto. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/zX9tjFgB/a850.png\"></center>\n",
    "\n",
    "Última nota, no olvides añadir la opción **`\"-dt\"`** para que el contenedor se ejecute en segundo plano.  Muy bien, ahora la configuración básica del nuevo nodo está hecha, podemos ejecutarlo pulsando Enter.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/2ShHXLQx/a851.png\"></center>\n",
    "\n",
    "Comprueba que el contenedor se está ejecutando con \"docker ps\".  Perfecto.  Antes de seguir adelante, vamos a abrir el Flower dashboard. Desde tu navegador web, escribe localhost:5555. Enter.  Como no iniciamos un celery worker desde el nuevo nodo, todavía tenemos un solo worker.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/JhyhLmhK/a852.png\"></center>\n",
    "\n",
    "Vuelve a tu terminal, conéctate al contenedor docker que acabamos de crear escribiendo **`\"docker exec -it\"`**, copia y pega el id del contenedor aquí, **`\"/bin/bash\"`**. Enter.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/8CGy8kwg/a853.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/1zKvyxYn/a854.png\"></center>\n",
    "\n",
    "Ahora estamos dentro del contenedor. Tenemos que exportar la variable de entorno **`AIRLFOW_HOME`** igual a donde queremos instalar Airflow que **`/usr/local/airflow`**.  Creamos un nuevo usuario \"airflow\" con el comando **`\"useradd -ms /bin/bash -d $AIRFLOW_HOME airflow\"`**.  Enter.  Luego instalamos Airflow con **`pip install \"apache-airflow`** corchetes, y añadimos los paquetes que necesitamos. celery, crypto, postgres y redis.  Luego especificamos la versión que queremos que es 1.10.6 así.  Entramos y esperamos a que se instale Airflow.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/L6N4ghYN/a855.png\"></center>\n",
    "\n",
    "Como este proceso tarda un poco en terminar, voy a pausar el vídeo ahora mismo y volveré cuando termine. Ok.  A continuación, escribimos **`\"airflow initdb\"`** para configurar Airflow con los ajustes básicos.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Jn6KBN8R/a856.png\"></center>\n",
    "\n",
    "Cambiamos los permisos de la carpeta dada por AIRFLOW_HOME para que el usuario airflow pase a ser el owner.  Tecleamos **`\"chown -R airflow: $AIRFLOW_HOME\"`**.  Enter.  Después ya podemos entrar con el usuario \"airflow\". **`\"su - airflow\"`** y como se puede ver en el prompt ahora estamos logueados como airflow.  Si tecleamos **\"ls\"**, obtendremos los archivos y carpetas correspondientes a nuestra instancia de Airflow. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DZyBZCtC/a857.png\"></center>\n",
    "\n",
    "Para mantener la misma configuración que el resto de nodos del cluster, vamos a modificar el archivo airflow.cfg.  Abra su editor de código y compruebe que se encuentra en la carpeta airflow-materials/airflow-section-5 y abra el archivo airflow.cfg en la carpeta mnt/airflow.  Muy bien. El primer parámetro que tenemos que establecer es **`sql_alchemy_conn`**.  Aquí, sólo tenemos que cambiar este valor por la cadena correspondiente a la conexión con la Postgres metadata database. Para ello, escribiremos \"**`postgresql+psycopg2://airflow:airflow`**\" correspondiente al login y password del usuario postgres.  \"**`@postgres:5432/airflow`**\" definiendo respectivamente el host, el puerto y la base de datos de postgres.  Básicamente, utilizamos los mismos valores de las variables de entorno que definimos en el archivo docker-compose para el servicio Postgres.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/wM1251xL/a858.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/sxbcT318/a859.png\"></center>\n",
    "\n",
    "A continuación, establecemos el parámetro executor a \"CeleryExecutor\".  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/q7pGbbMk/a860.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Lsv3rtnj/a861.png\"></center>\n",
    "\n",
    "El siguiente parámetro a cambiar es result_backend. Básicamente, cuando un trabajo termina, el executor necesita actualizar los metadatos del job.  Por lo tanto, insertará un mensaje en una base de datos que será utilizada por el scheduler para actualizar el estado de la tarea.  Así que como hicimos con el parámetro anterior, cambiamos el valor por \"**`db+postgresql://airflow:airflow@postgres:5432/airflow`**\".  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/W1L8rpBq/a862.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/htLr0Wny/a863.png\"></center>\n",
    "\n",
    "Fíjate que si quieres usar MySQL en lugar de postgres, bastaría con cambiar todas las referencias de postgres por mysql.  El último parámetro es broker_url que corresponde al sistema broker de mensajes utilizado para distribuir las tareas en el cluster.  Como estamos usando Redis sustituimos el valor por \"**`redis://:redispass@redis:6379/1`**\". Guardamos el archivo. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KzzDF1Mw/a864.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/rmPCpqGm/a865.png\"></center>\n",
    "\n",
    "De vuelta a la terminal, exportamos AIRFLOW_HOME igual a /usr/local/airflow.  Ok así que todo está configurado, es hora de añadir un nuevo nodo al cluster iniciando un worker Celery con el comando \"airflow worker\". Enter. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/QxWSHKyr/a866.png\"></center>\n",
    "\n",
    "Ok, ahora vamos al Flower dashboard, y como puedes ver, tenemos un nuevo nodo worker. Vamos a ejecutar un DAG para comprobar si funciona bien.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/PJvbp0KM/a867.png\"></center>\n",
    "\n",
    "Abre una nueva pestaña y ve a Airflow UI.  Activa el toggle del DAG parallel_dag y refresca la página.  Vuelve al Flower Dashboard, ¡y funciona!  Como puedes ver, ambos workers están ejecutando tareas.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/8s8Rhw0g/a868.png\"></center>\n",
    "\n",
    "**`Así que básicamente hemos incrementado el número de tareas ejecutadas en paralelo de una a dos.  Si añadimos un nuevo worker aumentaremos este número en tres y así sucesivamente.  Eso es lo que llamamos escalado horizontal`**.  Cuanta más máquinas añades, más recursos obtienes.  Muy bien.  Antes de pasar al siguiente vídeo me gustaría señalar dos cosas.  Primero, si tienes una tarea usando Spark, Hive o cualquier otra dependencia, no olvides que tienes que instalar esas dependencias en el nuevo nodo worker también.  De lo contrario, tu tarea fallará.  Como puedes imaginar, puede ser muy difícil de mantener si tienes muchos nodos y ninguna herramienta para automatizar las actualizaciones de tus dependencias.  \n",
    "\n",
    "En segundo lugar, ¿qué ocurre si un nodo worker deja de estar disponible?  Vamos a comprobarlo. En tu terminal, abre una nueva pestaña y escribe \"docker ps\".  Para que el nodo quede totalmente indisponible, como si se produjera un gran fallo del sistema, vamos a utilizar \"**`docker kill`**\" con el id del contenedor del worker que hemos creado.  Así. Enter.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/gcLB67x5/a869.png\"></center>\n",
    "\n",
    "Ahora puedes cerrar esta pestaña y comprobar el Flower dashboard.  Aquí, puedes ver que el worker está offline mientras que el otro worker sigue funcionando.  Observa que todavía había una tarea activa, como se muestra aquí, cuando se produjo el fallo.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Pq6FmszG/a870.png\"></center>\n",
    "\n",
    "La pregunta es, ¿qué ocurre cuando una tarea se está ejecutando en un nodo y este nodo se bloquea? Para obtener la respuesta, haz clic en \"tasks\" en la barra superior y ordena las tareas por estado haciendo clic aquí. La tarea en estado \"started\" corresponde aquí a la tarea activa del worker accidentado. En la columna \"args\" ten en cuenta el nombre de la tarea y la execution date que en mi caso es la siguiente.  Por supuesto estos valores serán diferentes en su máquina.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/28p9dxv5/a871.png\"></center>\n",
    "\n",
    "Ahora, ve a la interfaz de Airflow, haz clic en el DAG y busca la tarea con la misma execution date.  Esta.  Observe que la tarea está en estado de \"success\" como lo demuestra el cuadrado es de color verde.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/8zx7ss9x/a872.png\"></center>\n",
    "\n",
    "Pero si pulsamos sobre ella, vamos a los logs, podemos ver que no tenemos ningún output que nos diga que la tarea efectivamente tuvo éxito.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/KzwqHPHJ/a873.png\"></center>\n",
    "\n",
    "Además, si abrimos el Flower dashboard, copiamos la execution date y la pegamos en el cuadro de búsqueda. Podemos ver que la tarea nunca ha sido ejecutada por otro worker.  ¿Qué significa esto?\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/8PhKZrBm/a874.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/2yWcRqpm/a875.png\"></center>\n",
    "\n",
    "Bueno, cuando un nodo se bloquea durante la ejecución de una tarea, el estado de esa tarea puede ser failed, success o running dependiendo de cuándo se produzca el bloqueo.  Esto significa que el DAG puede bloquearse, ya que la tarea nunca termina de ejecutarse. Incluso si desde el Flower dashboard la tarea está en estado \"started\", siempre debes referirte a la vista tree view desde la interfaz de usuario de Airflow. Si tiene alguna duda o si su tarea está atascada, todavía puede reintentarla haciendo clic en ella desde la tree view, y haga clic en \"Clear\" Esto obligará a la tarea a ser reintentada con un nuevo estado fresco. Como buena práctica, siempre debe comprobar la salida dada por sus tareas para evitar errores que pueden causar inconsistencias en su data pipeline.  Además, se recomienda establecer un timeout así como un número de reintentos (retries) para tus tareas.  \n",
    "\n",
    "**Muy bien, así que hemos visto cómo crear manualmente un nuevo nodo, vamos a ver la manera fácil de hacerlo con docker-compose**. Volviendo al terminal, si escribimos \"**`Docker-compose -f docker-compose-CeleryExecutor scale worker=3`**\", como ya tenemos un worker en ejecución, Docker Compose añadirá dos nodos worker más a nuestro cluster. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/Z54f2Kwt/a876.png\"></center>\n",
    "\n",
    "Puedes comprobarlo volviendo al Flower dashboard, y como podemos ver, ahora tenemos tres nodos worker completamente funcionales.  \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/xCcp5xtX/a877.png\"></center>\n",
    "\n",
    "Esto es mucho más fácil y rápido que el método manual, pero realmente quería mostrarte cómo hacerlo sin Docker Compose.  Muy bien. Ahora tenemos tres nodos worker, en algún momento puede que quieras enviar algunas tareas a nodos específicos de acuerdo a sus recursos para que especialices tus nodos.  Eso es lo que vamos a descubrir en el siguiente video. Antes de seguir adelante, abre tu terminal y detén los contenedores docker escribiendo \"**`docker-compose -f docker-compose- CeleryExecutor.yml down`**\". Perfecto.  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
