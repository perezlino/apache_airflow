{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.5 - Backfilling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hablemos del backfilling, porque el backfilling es realmente importante. Imaginemos que hemos creado un data pipeline, pero queremos ejecutarlo en el pasado. Por ejemplo, ahora estás en el 1 de enero de 2021 y quieres ejecutarlo para el año anterior. ¿Cómo puede hacerlo? Si se especifica la start_date el 1 de enero de 2020, Airflow ejecutará automáticamente todas los DAG Runs no disparados entre la fecha actual, el 1 de enero de 2021, y la start_date, el 1 de enero de 2020, y este proceso se llama 'backfilling'. Se rellenan (backfill) automáticamente los datos para este periodo de tiempo. Esto es realmente útil porque, por ejemplo, si cometió un error en su DAG y tuvo que pausar su DAG durante cinco días, puede volver a ejecutar su DAG durante esos cinco días y esto lo hace automáticamente Airflow con el proceso de backfilling. Así de sencillo. Ahora puede controlar si quiere ejecutar ese proceso o no con el parámetro \"catchup\" en su DAG definition object, como una mejor práctica siempre establecerlo en \"False\". ¿Por qué? porque, de nuevo, imaginemos que tu start_date es de hace un año o quizás de hace dos meses, pero tu schedule_interval es muy ajustado. Si establece el parámetro \"catchup\" en \"True\", que es el valor por defecto, puede terminar con una tonelada de DAG Runs que se ejecutan al mismo tiempo, porque automáticamente Airflow tratará de ejecutar todas los DAG Runs no disparados en este momento, tan pronto como empiece a programar (scheduling) el DAG. Por lo tanto, es mejor evitar esto y tener un control total sobre su DAG y lo que hace. Dicho esto, puede modificar el valor por defecto del 'catchup parameter' en el archivo de configuración de Airflow con \"catchup_by_default\" y establecerlo en 'False'. **`Y una cosa que es absolutamente necesario recordar es que incluso si el 'catchup parameter' se establece en 'False' todavía se puede utilizar el proceso de backfilling. Básicamente, desde el Airflow CLI tienes este hermoso comando que es \"airflow dags backfill\"`** y luego especificas una start_date, por ejemplo, el 1 de enero de 2020 y luego la end_date y digamos el 1 de enero de 2021 y eso es todo. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/wB943dhp/a1089.png\"></center>\n",
    "\n",
    "Con este comando puedes rellenar (backfill) tu DAG, puedes rellenar tu data pipeline incluso si el \"catchup parameter\" está establecido en \"False\" pero de nuevo enviando ese \"catchup parameter\" a \"False\" estás evitando que se ejecuten todos esos DAG Runs no disparados automáticamente, lo cual es mucho mejor. \n",
    "\n",
    "Dos cosas más antes de pasar al siguiente vídeo. En primer lugar, si quieres evitar tener como una tonelada de DAG Runs corriendo al mismo tiempo, puedes usar un argumento dentro del dag definition object que es 'max_active_runs' y aquí puedes decir, digamos 1. Así que en ese caso, significa que no tendrás más de un DAG Run corriendo a la vez para ese DAG, desde my_dag. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/855yBBKX/a1090.png\"></center>\n",
    "\n",
    "Así que no dudes en aprovechar ese argumento es bastante útil especialmente cuando tienes dependencias entre tus DAG Runs. Por último, pero no menos importante, si vas a la interfaz de usuario de Airflow y vas a BROWSE > DAG RUNS, ten en cuenta que puedes volver a ejecutar perfectamente los DAG Runs disparados anteriormente utilizando la interfaz de usuario de Airflow. Lo único que tienes que hacer es pulsar en SEARCH > ADD FILTER > START DATE o EXECUTION DATE, así que vamos a hacerlo con la START DATE. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/QMS4TnbW/a1091.png\"></center>\n",
    "\n",
    "A continuación, añada una new feature, utilice el END DATE, haga clic en SEARCH y obtendrá la lista de todos los DAG Runs. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/L4qSmz9V/a1092.png\"></center>\n",
    "\n",
    "Seleccionas todos ellos haciendo clic aquí, haz clic en ACTIONS > CLEAR THE STATE, y al \"clearing the state\" vas a volver a ejecutar automáticamente esos DAG Runs. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/02DqwPJM/a1093.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/rw9Xfjjq/a1094.png\"></center>\n",
    "\n",
    "El último punto importante es que incluso si el parámetro \"catchup\" se establece en \"False\", tenga en cuenta que siempre se ejecuta la más reciente DAG Run no disparado, así que por ejemplo, si vas a DAGS y activas el Toggle para empezar a programar (scheduling) el DAG \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/h4HBvfhR/a1095.png\"></center>\n",
    "\n",
    "Y si actualizas la página, puedes ver que hay un DAG Run correspondiente al último, al más reciente DAG Run no disparado. Así que incluso con el 'catchup' establecido en 'False' podrías tener un DAG Run tan pronto como empieces a programar (scheduling) tu data pipeline.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/4xGRvqz8/a1096.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
