{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4.5 - The Celery Executor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Celery Executor es agradable para empezar a esbozar el número de tareas que se pueden ejecutar al mismo tiempo.\n",
    "\n",
    "¿Cómo?\n",
    "\n",
    "Mediante el uso de un celery cluster con el fin de ejecutar sus tareas en múltiples máquinas. \n",
    "\n",
    "Déjame mostrarte esto. Así que en primer lugar, usted todavía tiene el web Server, el Scheduler y la metadata database de airflow con Postgres. Pero como puedes ver, tienes componentes adicionales. El primero son los workers. En efecto, tienes los worker de airflow, que no son más que máquinas encargadas de ejecutar tus tareas. Así que en este caso, tienes tres workers, es decir, tres máquinas para ejecutar tus tareas. Si necesitas más recursos para ejecutar más tareas, sólo tienes que añadir un nuevo airflow worker y listo. Ahora la cola de celery se compone de dos cosas: el Backend de resultados, donde los airflow workers almacenan el estado de las tareas que se han ejecutado y el Broker, que no es más que una queue donde el Scheduler envía la tarea a ejecutar y los workers extraen (pull) las tareas de esa queue para ejecutarlas.\n",
    "\n",
    "Por ejemplo, quieres activar este DAG, el Scheduler envía la tarea T1 al broker, y luego uno de los workers extrae (pulls out) las tareas del broker para ejecutarlas.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/3wVmLmGB/a333.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/Gt1YRRqT/a334.png\"></center>\n",
    "\n",
    "Y una vez hecho, el estado de la tarea se almacena en el Result Backend, que no es más que la misma base de datos de airflow. O se puede utilizar otra base de datos si se quiere. Y finalmente la tarea se completa.\n",
    "\n",
    "Lo mismo para las demás tareas. Las T23 son empujadas (pushed) al broker por el Scheduler. Luego los workers toman las tareas para ejecutarlas. Por ejemplo, T2 en un worker y T3 en otro worker. Y finalmente los estados se almacenan en el Result Backend y se puede ver que se han completado. \n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/85vWxcBV/a335.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/C5H8L2QP/a336.png\"></center>\n",
    "<center><img src=\"https://i.postimg.cc/v8Wfz1Zr/a337.png\"></center>\n",
    "\n",
    "Solo hay que tener en cuenta que hay que instalar la celery queue que puede ser redis o rabbit in queue. Por ejemplo. Debido a esta queue necesitas definir la configuración adicional del celery result backend y la URL del celery broker. Eso es todo.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/DynsY2St/a338.png\"></center>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
