{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3.10 - Extras & Providers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una cosa que hay que tener en cuenta es que todo se construye de forma modular.\n",
    "\n",
    "**¿Qué significa esto?**\n",
    "\n",
    "Significa que cuando se instala airflow por primera vez, se instala Apache airflow core package que trae funcionalidades y operadores básicos como el operador Bash o el operador Python, que es muy bueno, pero tal vez no es suficiente. En efecto.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/zvPRn5hR/a141.png\"></center>\n",
    "\n",
    "**¿Y si quieres interactuar con AWS o Databricks o Snowflake o incluso Dbt?**\n",
    "\n",
    "Bueno, en este caso, vas a instalar **`Providers`**. Básicamente para AWS, quieres interactuar con él, necesitas instalar el provider `Amazon`. Eso es lo que se puede ver con **pip install apache-airflow-providers-amazon**. Desea interactuar con `Dbt` desde sus DAGs, es necesario instalar **pip install apache-airflow-providers-dbt-cloud** y así sucesivamente.\n",
    "\n",
    "<center><img src=\"https://i.postimg.cc/rFK4q06G/a142.png\"></center>\n",
    "\n",
    "Así que ten en cuenta esto, sólo con instalar esos Providers, añades nuevas funcionalidades e interacciones de tus data pipelines. Por eso airflow es tan potente. Es realmente extensible.\n",
    "\n",
    "Siempre que quieras interactuar con una herramienta, sólo tienes que instalar el proveedor correspondiente. Puedes echar un vistazo al enlace que aparece justo debajo si quieres ver cuántos proveedores tienes y cuáles son las herramientas con las que puede interactuar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **`Apuntes de Astronomer Apache Airflow Fundamentals`**\n",
    "\n",
    "Un Provider le permite añadir funcionalidades más allá de Airflow. Pero hay que saber que un Provider está completamente separado del Apache Airflow Core. Lo que significa que un Provider puede ser actualizado sin esperar a que Airflow sea actualizado. Por ejemplo, usted quiere interactuar con Postgres. Pues bien, si intenta crear una conexión y busca el tipo de conexión Postgres, no lo encontrará. ¿Por qué? Porque Postgres no está instalado por defecto, junto con Airflow. Así que tienes que instalar el Provider Postgres. Lo mismo ocurre con el PostgresOperator, si quieres utilizar el PostgresOperator, tiene que instalar el Provider Postgres. \n",
    "\n",
    "**`¿Cuál es la diferencia entre Extras y Providers?`**\n",
    "\n",
    "Los extras permiten instalar un conjunto de dependencias necesarias para una funcionalidad. Por ejemplo, usted quiere ejecutar sus tareas en Kubernetes, necesita instalar el extra de Kubernetes y como Kubernetes necesita un montón de diferentes dependencias para trabajar, pues todas esas dependencias se instalarán en su instancia de Airflow. Pero si usted sólo necesita algunos operators o hooks, puede simplemente instalar un Provider. Por ejemplo, si deseas interactuar con Postgres de nuevo, sólo tienes que instalar el Postgres package provider y obtendrá el operator de Postgres, así como el hook de Postgres.\n",
    "\n",
    "Bastante a menudo los Extras instalan providers también, pero no sólo los providers instalados, sino que añaden todas las dependencias necesarias para la funcionalidad que quieres añadir. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
